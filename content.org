#+TAGS: ignore(i) noexport(n)
#+PROPERTY: header-args :eval never-export
#+OPTIONS:   H:5 num:t toc:nil \n:nil @:t ::t |:t ^:t -:t f:t *:t <:t
#+OPTIONS:   TeX:t LaTeX:nil skip:nil d:nil todo:t pri:nil tags:not-in-toc

#+LaTeX: \newcounter{result}
#+LaTeX: \newenvironment{result}{\begin{boxedminipage}{\linewidth}\textit{\refstepcounter{result}\uline{Action \#\arabic{result}:}}\bf}{\end{boxedminipage}}
#+LaTeX: \let\leq=\leqslant
#+LaTeX: \let\geq=\geqslant


This paper reports the successful reproduction of the results in the
article \cite{velho:inria-00361031} entitled /Accuracy Study and
Improvement of Network Simulation in the SimGrid Framework/, which has
been published at the SimuTools 2009 conference. We detail several
pitfalls we stumbled upon during this reproduction process and report
the actions we took to improve the reproducibility of this work.

The first action we took is related to the visibility and availability
of the original article. Open access was not mandated by the funders of this
research at the time of publication. Even worse, we were regularly
told about constraining copyright issues from the editors and
discouraged to make our articles publicly available. Only the
bibliography entry was available on HAL and not the PDF. Yet the preprint was hosted
on the webpage of [[http://mescal.imag.fr/membres/pedro.velho/publications.html][both]] [[http://mescal.imag.fr/membres/arnaud.legrand/articles/simutools09.pdf][authors]] and visible mostly through the [[https://simgrid.org/publications.html][SimGrid
publication webpage]].

#+LaTeX: \begin{result} 
 The PDF version of the original article has thus been uploaded on
 [[https://hal.inria.fr/inria-00361031][HAL]] when engaging in the replication process.
#+LaTeX: \end{result}

* Historical Context
This article compares the accuracy of two methods for predicting how
competing TCP network flows interfere with each others. It is the
first article Arnaud Legrand wrote with his first PhD student Pedro
Velho. It was already a reproduction of the
work \cite{fujiwara2007speed} of close colleagues, Henri Casanova and
Kayo Fujiwara, and we already had faced difficulties in doing so at
that time. Actually, we could never obtain the exact same numbers as
them despite their care and ours. This failure motivated us to improve
our methodology, and in particular switching to [[https://www.r-project.org][R]] and later to [[https://www.orgmode.org][org-mode]], but it was 10 years
ago. Trying to reproduce this article was thus a good test of time!

** Scientific context
[[https://simgrid.org][SimGrid]] is a simulation toolkit designed to help with the performance
evaluation of large scale distributed computing systems such as
data/desktop grids, clusters or peer-to-peer systems. In this field,
it is common to resort to simulation which enables to explore many
application and platform scenarios, including platforms which do not
exist yet, and to obtain reproducible results (in theory).
Unfortunately, as noted in \cite{P2P_survey}, most researchers build
their own /ad hoc/ simulators which are rarely made (1) available ,
which hinders both reproducibility of results and comparison of
articles with one another, nor (2) validated, which makes final
results quite questionable. SimGrid is a 20-years old attempt to
provide a high quality simulation toolkit, which would be (1) stable
and perennial from a software point of view and (2) whose models would
be as validated as possible against reality and other simulators.

In this context, network simulation is certainly the most critical
part and packet-level simulation is often considered as particularly
realistic and faithful since they it allows to account for every
detail of network protocols. Unfortunately, such /microscopic/ approach is
undoubtedly interesting when studying peculiarities of network
protocols but it leads to prohibitively long simulation time when
studying large-scale distributed systems. An alternative is thus to
simulate networks by relying on higher level /macroscopic/ models, thus
enabling much faster simulation at the potential cost of an accuracy
loss. SimGrid, uses a flow-level approach that approximates the
behavior of TCP networks, including TCP's bandwidth sharing
properties. A preliminary study of the accuracy loss by comparing it
to popular packet-level simulators has been proposed by Fujiwara and Casanova
in \cite{fujiwara2007speed} and in which regimes in which SimGrid's
accuracy was comparable to that of these packet-level simulators were
identified. The article we reproduce here \cite{velho:inria-00361031}
was a reproduction these experiments and provided a deeper analysis
that enabled to greatly improve SimGrid's range of validity.

The interconnection network is modeled as a graph where nodes represent hosts while
edges represent network links. In SimGrid's flow-level modeling, the
time needed to transfer a message of size $S$ between hosts $i$ and
$j$ is given by:
#+BEGIN_EXPORT latex
\begin{equation}
  \label{eq:linearity}
  T_{i,j}(S) = L_{i,j} + S/B_{i,j},
\end{equation}
#+END_EXPORT
where $L_{i,j}$ (resp. $B_{i,j}$) is the end-to-end network latency
(resp. bandwidth) on the route connecting $i$ and $j$. Although
determining $L_{i,j}$ may be straightforward, estimating the bandwidth $B_{i,j}$
is more difficult as it depends on interactions with
every other flow. This is generally done by assuming that the flow has
reached /steady-state/, in which case the simulation amounts to
solving a bandwidth sharing problem, i.e., determining how much
bandwidth is allocated to each flow. 

#+LaTeX: \def\L{\ensuremath{\mathcal{L}}\xspace}
#+LaTeX: \def\F{\ensuremath{\mathcal{F}}\xspace}
More formally, consider a connected network that consists of a set of
links \L, in which each link $l$ has capacity $B_l$. Consider a set of
flows \F, where each flow is a communication between two network
vertices along a given path. Determine a ``realistic'' bandwidth
allocation $\rho_f$ for flow $f$, so that:
#+BEGIN_EXPORT latex
  \begin{equation}
    \label{eq:cnsts}
    \forall l\in\L, \sum_{\text{$f$ \text{going through} $l$}} \rho_f \leq
    B_l\;.
  \end{equation}
#+END_EXPORT
In SimGrid, the ``realistic'' bandwidth sharing
model \cite{rr-lip2002-40} used is Max-Min
fairness \cite{massoulie99bandwidth}, which is reached by recursively
maximizing
#+BEGIN_EXPORT latex
  \begin{equation}
  \min_{f\in\F} w_f \rho_f \quad \text{under
    constraints in Eq.~\eqref{eq:cnsts},}\;
  \label{OptMaxmin}
\end{equation}
#+END_EXPORT
where $w_f$ is generally chosen as the round-trip time of flow
$f$. This objective corresponds to what one would naively expect
from a network, i.e. be ``as fair as possible'' so that the least
favored flows receive as much bandwidth as possible while accounting
through weights $w_f$ for the well-known RTT-unfairness of
TCP \cite{rtt-fairness}.

Given the computed bandwidth allocation (which defines all data
transfer rates), and the size of the data to be transmitted by each
flow, one can determine which flow will complete first. Upon
completion of a flow, or upon arrival of a new flow, the bandwidth
allocation can be reevaluated. Compared to a packet-level simulation,
this approach allows to quickly step-forward in time when large data
transfers are involved. However, since steady-state is assumed, it
ignores many transient aspects such as throughput oscillations and
slow start. This (in)validation work was later extended to compare with other
bandwidth sharing models \cite{velho:hal-00872476} and has been the
core of the PhD thesis of Pedro
Velho \cite{madeiradecamposvelho:tel-00625497}.

In the article we reproduce, the accuracy of the /flow-level/
simulations of SimGrid are compared to the /packet-level/ simulations of
GTNetS \cite{GTNetS} the Georgia Tech Network Simulator. This was done
through three series of simulations
1. One-link: The first set of experiments is for a single TCP flow
   going through a single link with varying physical *latency* and
   *bandwidth*, and message *size*. The main goal of this scenario was to
   study the size for which transient effects such as slow start are
   negligible.
2. A Dumbell Topology: The second set of experiments is for two TCP
   flows A and B on a dumbbell topology with varying *bandwidth* of the
   inner link and *latency* of the end-link used by flow B. The main
   goal of this scenario was to study the ability of accounting for
   RTT-unfairness.
3. Random Topology: 4 sets of 10 random topologies generated with a
   topology generator were used. The sets comprised either /small/ (50
   nodes) or /large/ (200 nodes) and either relatively /homogeneous/ or
   /heterogeneous/ platforms. 200 flows were generated between random
   pairs of end-points in the topology, which all start simultaneously
   and communicate 100MB of data. The main goal of this scenario was to
   evaluate the overall accuracy of SimGrid and possibly to detect
   corner-case situations for which the SimGrid model was particularly
   wrong.

Due to the long simulation time, we only reproduce in this article the
first series of simulation but we checked that we could easily run at
least one simulation of the two other series.
** Computational context
\label{sec:comp.context}
[[https://simgrid.org/][SimGrid]] is mostly written in =C= while [[http://griley.ece.gatech.edu/MANIACS/GTNetS/][GTNetS]] is mostly written in =C++=
and both are open source simulators. Although SimGrid is designed to
be as stand alone as possible, GTNetS relies on third party
libraries. *The first challenge would thus be to reproduce a software
environment allowing to recompile and rerun both libraries*.

To ease the comparison of both simulators, SimGrid had been modified
to run GTNetS internally, which allowed to easily switch between the
microscopic (GTNetS) model and the macroscopic (Max-Min) model from
the command line, while using the exact same platform description and
communication scenario. This integration required modifying both
SimGrid and GTNetS and was done through a set of patches before being
partly integrated in the main branch of SimGrid.
*The second challenge would thus be to manage to correctly modify and
recompile a simulator using both libraries.*

   #+BEGIN_EXPORT latex
   \begin{figure}[!h]
     \includegraphics[width=\linewidth]{figures/workflow.pdf}
     \caption{The simulation workflow}
     \label{fig:workflow}
   \end{figure}
   #+END_EXPORT

Although these details were not given in the articles, it could be
recovered from one of the README we found (see
Figure \ref{fig:README1} and Figure \ref{fig:README4}) and the general
workflow of the simulations for all three scenarios was as follow
(see Figure \ref{fig:workflow}):
- A simple =C= code called =gtnets.c= was linked against SimGrid and
  GTNetS;
- A =perl= script called =sweep-parse.pl= (when called with the =sweep=
  argument) would generate platform and flow/deployment =XML= input
  files and run all simulations by passing the previous =XML= input file
  to the =gtnets= binary with a different command line argument to
  switch between the GTNetS model and the Max-Min model. The
  simulation would produce a text output.
- The same =perl= script (when called with the =parse= argument) would
  then parse all the text logs and produce a =csv= data file.
- The data file would then be analyzed with an =R= script and since our
  mastery of =R= was quite low at that time, we still relied on gnuplot
  to generate figures.

*The third challenge would thus be to manage to run all this workflow,
provided the right instructions could be found.*

Note that although the first two series of experiments did not have
much external dependencies, the third one relied on many random
network topologies generated by BRITE \cite{brite}, which is a
discontinued =Java= software, using the Waxman model \cite{Waxman88}. The
description of the parameters used to generate the topologies were
shallow and there was no information regarding seeds so our hope to
rerun this software to regenerate the same topologies was quite
low. However, theses intermediate files may have been stored and made
available. *The fourth challenge would thus be to recover the network
topology and data used in the third series of experiments*.

* Rebuilding the code and its environment
** Original source code and retrieval of the software
*** Instructions
 Although the development of SimGrid is still very active, GTNetS'
 development appears to be discontinued as the last version of GTNetS
 dates back October 2008. Finding both source code is relatively easy
 however, the main difficulty was to find the instructions and to know
 which version to use. SimGrid has successively moved from the [[https://gforge.inria.fr/projects/simgrid/][Inria
 gforge]] to the [[https://gitlab.inria.fr/simgrid/simgrid/][Inria gitlab]], [[http://github.com/simgrid/simgrid/][GitHub]], and more recently
 [[https://framagit.org/simgrid/simgrid/][Framagit]]. Although the whole software history has been correctly moved
 in the process, we realized some information have not been transfered
 and even sometimes lost:
 - Although we could have used a development version of SimGrid from
   late 2009, we thought it would be simpler to reproduce this work
   using a stable release which integrates the GTNetS support (e.g.,
   the version 3.3, which dates from April 2009). Unfortunately, the
   [[https://github.com/simgrid/simgrid/releases?after=v3_8_1][releases of SimGrid on GitHub]] only start from May 2010. Indeed,
   although the SimGrid project started in 2000, its git history only
   starts in 2004 as the CVS history was not migrated to SVN (it was
   considered of little interest). Later, when the development team decided
   to migrate from SVN to git (in 2010), the SVN tags have not been
   transferred. Likewise, when the project migrated from the Inria
   gforge, not all releases (as an archive) of SimGrid were
   transferred. Fortunately, all the old releases of SimGrid are still 
   available on the [[https://gforge.inria.fr/projects/simgrid/][Inria gforge]].

   #+LaTeX: \begin{result} 
     We have thus now uploaded the original release of SimGrid version 3.3 on [[https://github.com/simgrid/simgrid/releases/tag/v3.3][Github]].
   #+LaTeX: \end{result}
   This upload is mostly manual and will be done for other old releases
   as soon as possible.
 - The \LaTeX source of the article is stored in the private [[https://gforge.inria.fr/scm/?group_id=862][Inria
   Gforge simgrid-publis]] project, in an =svn= under the
   =PUBLISHED/09_validation_simutools= directory. 

   #+LaTeX: \begin{result} 
     We have now made the \LaTeX source of the article available in
     the [[https://github.com/alegrand/reproducibility-challenge/tree/master/simutools09/article/][github repository attached to this Rescience submission]].
   #+LaTeX: \end{result}
 - We remembered that we had made our instructions on how conduct these
   experiments available somewhere but no link was given in the
   original article and we could not really remember where it was as
   there was no standard way of doing so back then. We initially thought they were
   given on the former =contrib/= section of
   http://simgrid.gforge.inria.fr/ (, which was hard to maintain and
   was thus abandoned) or on http://simgrid-publis.gforge.inria.fr/ (,
   which finally only hosts data on two articles from 2011). However
   even after inspecting the [[https://web.archive.org/web/20091120124838/http://simgrid.gforge.inria.fr/doc/contrib.html][Internet Archive]], we could not find it.

   Arnaud Legrand therefore tried to find them on his laptop but although he
   could find many related files (including the topology generators)
   he failed finding the right data and doing so, he realized many the
   data of some of his previously published articles were dangling
   links and had not been correctly transferred when migrating from a
   laptop to an other! The instructions could probably have been
   recovered on his backup hard drives but he had the chance to meet Pedro
   Velho and to ask him whether his own backups were in better shape,
   which was fortunately the case. Pedro Velho could find all the
   required data (a 61MB zip archive) and shared it with him. 
   It turned out that we later realized that this archive was
   also simply available from [[http://mescal.imag.fr/membres/pedro.velho/publications.html][Pedro Velho's former webpage]], which is still
   available but which is not highly ranked on search engines and
   which he cannot modify anymore as he now works for a different
   company.

   #+LaTeX: \begin{result} 
     We have now made the instructions and data used in the original
     article available in the [[https://github.com/alegrand/reproducibility-challenge/tree/master/simutools09/instructions][GitHub repository attached to this Rescience submission]].
   #+LaTeX: \end{result}

   This archive comprises 3 sub-archives corresponding to each of the
   3 series of simulations mentioned earlier (=01-onelink.tgz=,
   =02-dumbbell.tgz=, =03-random.tgz=) as well as a GTNetS version
   (=GTNetS-Oct-10-08.tar.gz=) and the master simulation file (=gtnets.c=)
   which should be compiled against SimGrid and GTNetS. The README
   that can be found in each sub-archive (see
   Figure \ref{fig:README4}) describes in details how to 
   rerun the experiments and corresponds to the process described in
   Section \ref{sec:comp.context}. A good surprise was that
   the third archive contained all the random graphs used in the
   simulation, hence saving us the burden of trying to regenerate them
   with BRITE. Unfortunately, the master README
   (see Figure \ref{fig:README1}) provides information about dates and
   the contents of the archive but most information related to
   software versions are broken (it was a working version, which we
   intended to consolidate when the article would be
   accepted). Furthermore, after having compiled GTNetS and a thorough
   inspection of the source code, we realized it did not seem to have
   been modified to work with SimGrid.
 - Arnaud Legrand therefore started searching again for GTNetS
   versions that would be on his laptop and finally found one, along
   with all the patches and compiling instructions which are crucial
   to correctly build such prototype software (see
   Figure \ref{fig:README2}). These information were actually public
   but had become completely hidden in the (now unmaintained and long
   forgotten) contrib section of the SVN (while git is now the default
   version manager) of the Inria Gforge SimGrid project.

   #+LaTeX: \begin{result} 
   *We have now ensured that the GTNetS version and the patches we
   used are archived on Software Heritage.*\footnote{The save request was done on 4/30/2020, 6:50:02 PM but it is still pending.}
   #+LaTeX: \end{result}

   #+BEGIN_EXPORT latex
   \begin{figure}[!h]
     \includegraphics[width=\linewidth]{figures/archives.pdf}
     \caption{The three archives required to reproduce this work.}
     \label{fig:archives}
   \end{figure}
   #+END_EXPORT

In the end, we have thus managed to recover three important archives
(see Figure \ref{fig:archives}),
whose versions should be the one run to produce the results of the
original SimuTools 2009 article:
1. The stable release =v3.3= of SimGrid (from April 2009) from the public
   Inria Gforge. Although experiments were probably run in late 2008,
   the previous stable SimGrid release is from 2007 and =v3.3=
   incorporates everything that was needed.
2. A snapshot of GTNetS from January 2008 along with the patches to
   apply from the public Inria Gforge SimGrid project but which was
   not visible anymore.
3. The simulation instructions and data, from one of the author's hard
   drive although they were also available from his website but both
   authors had forgotten about it.
Almost no information regarding the software environment was available
except that it was run on a Debian in the late 2008 (see Figure \ref{fig:README2}).
   #+BEGIN_EXPORT latex
   \begin{figure}[!htbp]
     \centering
     \VerbatimInput[label=\fbox{\color{black}simutools09/instructions/README}]{simutools09/instructions/README}
     \caption{The README which accompanies instructions recovered from Pedro Velho on the 
          simulation workflow are very helpful to understand the general process but 
          lack important version information.}
     \label{fig:README1}
   \end{figure}
   #+END_EXPORT
   #+BEGIN_EXPORT latex
   \begin{figure}[!htbp]
     \centering
     \VerbatimInput[label=\fbox{\color{black}simutools09/instructions/01-onelink/README}]{simutools09/instructions/01-onelink/README}
     \caption{The README which ships with the first set of experiments (\texttt{01-onelink.tgz}).}
     \label{fig:README4}
   \end{figure}
   #+END_EXPORT
   #+BEGIN_EXPORT latex
   \begin{figure}[!htbp]
     \centering\vspace{-.5cm}
     \VerbatimInput[framesep=1em, label=\fbox{\color{black}simutools09/README.patching\_GTNetS}]{simutools09/README.patching_GTNetS}
     \centering\vspace{-.5cm}
     \caption{The README which accompanies the GTNetS patches provides many critical information on
          how to compile GTNetS and SimGrid.}
     \label{fig:README2}
   \end{figure}
   #+END_EXPORT

** Rebuilding the software environment
SimGrid is mostly a C library whose software dependencies had at that
time been kept to the bare minimum (C and C++ compiler). Furthermore,
we are developers of the SimGrid library so building it was rather
straightforward even on a recent Linux distribution. 
However, after trying to compile GTNetS, we quickly realized
it depends on the Qt3 GUI Library whereas the version which is now
commonly found is Qt5! Therefore, we decided to recreate a minimal
software environment as close as possible to the one of 2008. 

The code name for the stable Debian distribution at that time was
/Lenny/ Debian provides two particularly interesting tools to reproduce
"old" environments:
1. The [[https://snapshot.debian.org/][Debian snapshot archive]] is a wayback machine that allows access to
   old packages based on dates and version numbers. It consists of all
   past and current packages the Debian distribution ever provided.
2. The [[https://github.com/debuerreotype/debuerreotype][Debuerreotype]] is a reproducible, snapshot-based Debian rootfs
   builder. It allows to prepare old Debian images from the
   snapshot archive, which is particularly useful to prepare Docker
   images containing old software environments.

Both authors regularly used =testing= so after investigating a bit
on the snapshot archive which versions of the libraries were available
and when they have been introduced, we decided to try to bootstrap a
debian Lenny from the 1st of May 2009 with the following command:
#+LaTeX: \bgroup\footnotesize
#+begin_src shell :session *shell* :results output :exports both
debuerreotype-init --keyring=/usr/share/keyrings/debian-archive-removed-keys.gpg \
   rootfs testing 2009-05-01-T03:27:08Z
#+end_src
#+LaTeX: \egroup
Building such an image involves installing (with =dpkg=) old packages in
a sub-directory pretending you are root. The =keyring= argument passed to
=debuerreotype-init= allows to indicate =dpkg= that it is safe to install
these old packages even if they have been signed by package
maintainers which are currently not active anymore. Unfortunately,
although this approach worked like a charm for more recent target
#+LaTeX: dates (e.g., \texttt{2015-06-04-\discretionary{}{}{}T10:47:50Z}), 
it miserably fails with a "Segmentation fault" when installing
=base-passwd:=
#+LaTeX: \bgroup\footnotesize
#+BEGIN_EXAMPLE
W: Failure trying to run: chroot "/home/alegrand/Work/Documents/Articles/2020/
        reproducibility_challenge/simgrid3.3_gtnets/rootfs" dpkg --force-depends 
             --install /var/cache/apt/archives/base-passwd_3.5.21_amd64.deb
W: See /home/alegrand/Work/Documents/Articles/2020/reproducibility_challenge/
         simgrid3.3_gtnets/rootfs/debootstrap/debootstrap.log for details

error: 'debootstrap' failed!
#+END_EXAMPLE
#+LaTeX: \egroup

We then decided to cry for help and asked two Debian guru friends,
Vincent Danjean and Samuel Thibault. Samuel Thibault indicated us that
he had investigated this by using the simpler following command:
#+LaTeX: \bgroup\footnotesize
#+begin_src shell :results output :exports both
  debootstrap wheezy myroot http://archive.debian.org/debian/
#+end_src
#+LaTeX: \egroup
and that the error message was then slightly more visible
#+LaTeX: \bgroup\footnotesize
  #+BEGIN_EXAMPLE
  dpkg: warning: parsing file '/var/lib/dpkg/status' near line 5 package 'dpkg':
   missing description
  
  Package: dpkg
  Status: install ok installed
  Maintainer: unknown
  Version: 1.16.18
  #+END_EXAMPLE
#+LaTeX: \egroup
The problem actually comes from =dpkg=. When bootstraping such an image,
we try to use old debian packages with a recent =dpkg= (the one running
on our machine) so it is not surprising that it may break. Although it
is not the case, the internal format of Debian packages could have evolved and may not
be supported anymore with recent versions of =dpkg=. Likewise, it is
somehow a matter of luck that an old binary still works with a recent
kernel... Indeed, when using docker or similar container-based
approach, we only divert syscalls so if the ABI of the Linux kernel
had changed in the meantime, binary codes would simply fail to
run. Fortunately, such changes are quite rare and the Linux/Debian
community is making incredible efforts to provide super stable
backward compatible software so what could be the reason behind this
failure?

Surprisingly Vincent Danjean reported me that the command worked like
a charm for him, which means some local configuration from
his machine could change this behavior. We could actually track back
the problem to an ABI modification of the kernel. As explained for
example on the [[https://einsteinathome.org/content/vsyscall-now-disabled-latest-linux-distros][Einstein@Home forum]], \bgroup\em"On latest Linux distros, =vsyscall=
is defaulted to none for security reasons. However, this breaks some
very old binaries, including some binaries from this project that are
statically-linked against ancient versions of =glibc="\egroup. Vincent had
activated this flag a long time ago to run some old proprietary code.
Booting the machine while adding ~vsyscall=emulate~ to the kernel
command line solved the problem and allows ~debuerreotype~ to build the
desired =rootfs=.

Since this is a bit far-fetched, we decided to trade precision for
simplicity by checking whether ready-to-use Docker images were
available on the Docker Hub, [[https://hub.docker.com/r/lpenz/debian-lenny-i386/][which is the case]].
#+begin_src shell :results output :exports both
docker search debian-lenny
#+end_src

#+RESULTS:
: NAME                               DESCRIPTION                                     STARS
: pblaszczyk/debian-lenny            5.0.10 amd64                                    3                                       
: lpenz/debian-lenny-amd64           Debian 5.0.10 Released 10 March 2012 for amd…   1                                       
: lpenz/debian-lenny-i386            Debian 5.0.10 Released 10 March 2012 for i386   1                                       
: lpenz/debian-lenny-amd64-minbase   Debian 5.0.10 Released 10 March 2012 for amd…   0                                       
: ...

Note that the first version of Lenny (5.0.0) was introduced in
February 2009 whereas the one easily found on the DockerHub is the
last version (5.0.10) which dates from March 2012. The main
differences are related to security updates and should be of not
importance for our concern. We arbitrarily chose the
=lpenz/debian-lenny-i386= one but according to the instructions of
Figure \ref{fig:README2} =lpenz/debian-lenny-amd64= should have worked
as well. After playing a bit interactively in this Docker image
trying to install everything we needed to build GTNetS and SimGrid,
and following the patching and compiling instructions, we ended up
with the =Dockerfile= presented in Figure \ref{fig:dockerfile}. 
The image can be simply built with the following command:
#+begin_src shell :results output :exports both
docker build -t alegrand/simgrid3_3_gtnets simgrid3.3_gtnets
#+end_src

   #+BEGIN_EXPORT latex
   \begin{figure}[!thb]
     \centering
     \VerbatimInput[label=\fbox{\color{black}simutools09/simgrid3.3\_gtnets/Dockerfile}]{simutools09/simgrid3.3_gtnets/Dockerfile}
     \caption{The Dockerfile recipe which allows to build both GTNetS and Simgrid}
     \label{fig:dockerfile}
   \end{figure}
   #+END_EXPORT

#+LaTeX: \begin{result} 
  We have now proposed a simple and automated way to build a minimalist environment
  comprising the simulation code used in the original article. This
  =Dockerfile= recipe has been made available in the [[https://github.com/alegrand/reproducibility-challenge/tree/master/simutools09/simgrid3.3_gtnets/][GitHub repository
  attached to this Rescience submission]]. The resulting docker image
  has been made available on the [[https://hub.docker.com/repository/docker/alegrand38/simgrid3_3_gtnets][DockerHub]]. It can be recovered using:\rm
  #+begin_src shell :results output :exports both
  docker pull alegrand38/simgrid3_3_gtnets
  #+end_src
#+LaTeX: \end{result}

Note that, as such, this =Dockerfile= is still a bit fragile as it
depends on a third party base image (=lpenz/debian-lenny-i386=) and
downloads the code from =gforge.inria.fr=. Ideally, it would be improved
to build on my own =debuerreotype= image for a specific date and to
download the code from [[https://www.softwareheritage.org/][software heritage]]. We propose to leave this for
the next reproducibility challenge in a decade or so.

* Execution and reproduction of results
\label{sec:workflow}
** Expectations
   Following the information from the README of each series of
   simulations (see Figure \ref{fig:README4}), we could easily
   determine which scripts to run (=sweep-parse.pl=). It is interesting
   to note that the logs of each simulation were stored in the archive
   (in =log/=) as well as the parsing of these logs (in =dat/=).

Before trying to rerun all this, we ensured a specific parameter
combination could be run to manually check whether outputs are matching
or not. Here was the target:

#+begin_src shell :results output :exports both
head -4 simutools09/instructions/01-onelink/dat/raw.data
#+end_src

#+RESULTS:
: Bandwidth Latency Size Model Time
: 1 1.000000e+05 0.00001 1000 CM02 0.010010
: 2 1.000000e+05 0.00001 1000 GTNets 0.013140
: 3 1.000000e+05 0.00001 1000 LegrandVelho 0.010974

And here was the output we should get from running =gtnets=.\label{expected-output}
#+begin_src shell :results output :exports both
head -46 simutools09/instructions/01-onelink/log/trace-file-1-1.log
#+end_src

#+RESULTS:
#+begin_example
>==================================================<
========> Bandwidth (B) : 1.000000e+05 B/s (Bytes per second)
========> Latency   (L) : 0.00001 s (seconds)
========> Size      (S) : 1000 B (Bytes) 
========> Model     (M) : CM02
[0.000000] [simix_kernel/INFO] setting 'workstation_model' to 'compound'
[0.000000] [xbt_cfg/INFO] type in variable = 2
[0.000000] [simix_kernel/INFO] setting 'cpu_model' to 'Cas01'
[0.000000] [xbt_cfg/INFO] type in variable = 2
[0.000000] [simix_kernel/INFO] setting 'network_model' to 'CM02'
[0.000000] [xbt_cfg/INFO] type in variable = 2
[S1:master:(1) 0.010010] [msg_test/INFO] Send completed (to C1). Transfer time: 0.010010
	 Agregate bandwidth: 99900.099900
[S1:master:(1) 0.010010] [msg_test/INFO] Completed peer: C1 time: 0.010010
[C1:slave:(2) 0.010010] [msg_test/INFO] ===> Estimated Bw of FLOW[1] : 99900.099900 ;
  message from S1 to C1  with remaining : 0.000000
=========================><=========================
>==================================================<
========> Bandwidth (B) : 1.000000e+05 B/s (Bytes per second)
========> Latency   (L) : 0.00001 s (seconds)
========> Size      (S) : 1000 B (Bytes) 
========> Model     (M) : GTNets
[0.000000] [simix_kernel/INFO] setting 'workstation_model' to 'compound'
[0.000000] [xbt_cfg/INFO] type in variable = 2
[0.000000] [simix_kernel/INFO] setting 'cpu_model' to 'Cas01'
[0.000000] [xbt_cfg/INFO] type in variable = 2
[0.000000] [simix_kernel/INFO] setting 'network_model' to 'GTNets'
[0.000000] [xbt_cfg/INFO] type in variable = 2
[S1:master:(1) 0.013140] [msg_test/INFO] Send completed (to C1). Transfer time: 0.013140
	 Agregate bandwidth: 76103.500761
[S1:master:(1) 0.013140] [msg_test/INFO] Completed peer: C1 time: 0.013140
[C1:slave:(2) 0.013140] [msg_test/INFO] ===> Estimated Bw of FLOW[1] : 76103.500761 ;
  message from S1 to C1  with remaining : 0.000000
=========================><=========================
>==================================================<
========> Bandwidth (B) : 1.000000e+05 B/s (Bytes per second)
========> Latency   (L) : 0.00001 s (seconds)
========> Size      (S) : 1000 B (Bytes) 
========> Model     (M) : LegrandVelho
[0.000000] [simix_kernel/INFO] setting 'workstation_model' to 'compound'
[0.000000] [xbt_cfg/INFO] type in variable = 2
[0.000000] [simix_kernel/INFO] setting 'cpu_model' to 'Cas01'
[0.000000] [xbt_cfg/INFO] type in variable = 2
[0.000000] [simix_kernel/INFO] setting 'network_model' to 'LegrandVelho'
[0.000000] [xbt_cfg/INFO] type in variable = 2
[S1:master:(1) 0.010974] [msg_test/INFO] Send completed (to C1). Transfer time: 0.010974
	 Agregate bandwidth: 91128.086469
[S1:master:(1) 0.010974] [msg_test/INFO] Completed peer: C1 time: 0.010974
[C1:slave:(2) 0.010974] [msg_test/INFO] ===> Estimated Bw of FLOW[1] : 91128.086469 ;
  message from S1 to C1  with remaining : 0.000000
=========================><=========================
#+end_example

** Running the simulation in the Docker image
As the reader may have noted, the Docker image we produced only
contains the binary code of the simulator but not the input files nor
the perl script to run simulations. This is an intended separations of
concerns and we believe it is a good practice to keep images as
lightweight as possible and easier to maintain. We now describe how
to rerun the simulation. We should first run the docker
container.
#+begin_src shell :session *shell* :results output :exports both 
docker run -ti alegrand38/simgrid3_3_gtnets
#+end_src
# #+begin_src shell :session *shell* :results output :exports both 
# mkdir -p /root/simutools09/01-onelink
# #+end_src
Then the template XML input files should be copied within the container (=$CONTAINER=
corresponds to the container id of the container and is obtained
either using =docker ps= or by querying the =hostname= within the
container).
#  :var CONTAINER=container
#+begin_src shell :results output :exports both
docker cp simutools09/instructions/01-onelink/onelink-d-template.xml \
       $CONTAINER:/root/simutools09/01-onelink
docker cp simutools09/instructions/01-onelink/onelink-p-template.xml \
       $CONTAINER:/root/simutools09/01-onelink
#+end_src
It is then possible to substitute the target parameters in these XML
files and to run the simulation in the container:
#+begin_src shell :session *shell* :results output :exports both 
cd /root/simutools09/01-onelink
sed -e s/bw/1.000000e+05/g -e s/lt/0.00001/g onelink-p-template.xml \
    > /tmp/onelink-p.xml
sed -e s/size/1000/g onelink-d-template.xml > /tmp/onelink-d.xml
for model in CM02 GTNets LegrandVelho; do
    echo ">==================================================<"
    echo "========> Model     (M) : $model"
    /root/simgrid-3.3/examples/msg/gtnets/gtnets              \
       /tmp/onelink-p.xml  /tmp/onelink-d.xml                 \
       --cfg=workstation_model:compound --cfg=cpu_model:Cas01 \ 
       --cfg=network_model:$model;
done;
#+end_src

#+RESULTS:
#+begin_example
>==================================================<
========> Model     (M) : CM02
echo 'org_babel_sh_eoe'
echo 'org_babel_sh_eoe'
[0.000000] [simix_kernel/INFO] setting 'workstation_model' to 'compound'
[0.000000] [xbt_cfg/INFO] type in variable = 2
[0.000000] [simix_kernel/INFO] setting 'cpu_model' to 'Cas01'
[0.000000] [xbt_cfg/INFO] type in variable = 2
[0.000000] [simix_kernel/INFO] setting 'network_model' to 'CM02'
[0.000000] [xbt_cfg/INFO] type in variable = 2
[S1:master:(1) 0.010010] [msg_test/INFO] Send completed (to C1). Transfer time: 0.010010
	 Agregate bandwidth: 99900.099900
[S1:master:(1) 0.010010] [msg_test/INFO] Completed peer: C1 time: 0.010010
[C1:slave:(2) 0.010010] [msg_test/INFO] ===> Estimated Bw of FLOW[1] : 99900.099900 ;
  message from S1 to C1  with remaining : 0.000000
>==================================================<
========> Model     (M) : GTNets
[0.000000] [simix_kernel/INFO] setting 'workstation_model' to 'compound'
[0.000000] [xbt_cfg/INFO] type in variable = 2
[0.000000] [simix_kernel/INFO] setting 'cpu_model' to 'Cas01'
[0.000000] [xbt_cfg/INFO] type in variable = 2
[0.000000] [simix_kernel/INFO] setting 'network_model' to 'GTNets'
[0.000000] [xbt_cfg/INFO] type in variable = 2
<<<<<================================>>>>>
Dumping GTNETS topollogy information
== LINKID: 0
  [SRC] ID: 0, router?: 0, hosts[]: [ 0]
  [DST] ID: 1, router?: 0, hosts[]: [ 1]
>>>>>================================<<<<<
[S1:master:(1) 0.013140] [msg_test/INFO] Send completed (to C1). Transfer time: 0.013140
	 Agregate bandwidth: 76103.500761
[S1:master:(1) 0.013140] [msg_test/INFO] Completed peer: C1 time: 0.013140
[C1:slave:(2) 0.013140] [msg_test/INFO] ===> Estimated Bw of FLOW[1] : 76103.500761 ;
  message from S1 to C1  with remaining : 0.000000
>==================================================<
========> Model     (M) : LegrandVelho
[0.000000] [simix_kernel/INFO] setting 'workstation_model' to 'compound'
[0.000000] [xbt_cfg/INFO] type in variable = 2
[0.000000] [simix_kernel/INFO] setting 'cpu_model' to 'Cas01'
[0.000000] [xbt_cfg/INFO] type in variable = 2
[0.000000] [simix_kernel/INFO] setting 'network_model' to 'LegrandVelho'
[0.000000] [xbt_cfg/INFO] type in variable = 2
[S1:master:(1) 0.010974] [msg_test/INFO] Send completed (to C1). Transfer time: 0.010974
	 Agregate bandwidth: 91128.086469
[S1:master:(1) 0.010974] [msg_test/INFO] Completed peer: C1 time: 0.010974
[C1:slave:(2) 0.010974] [msg_test/INFO] ===> Estimated Bw of FLOW[1] : 91128.086469 ;
  message from S1 to C1  with remaining : 0.000000
#+end_example
We could thus recover exactly the expected values which are reported on page \pageref{expected-output}.

** Replicating the first series of simulations
Using the perl script should thus allow to re-execute the
simulation. It comprises hard-coded absolute paths and
a quick minor modification had thus to be made. Here is how to proceed:
- Within the container, we first create the directories that will
  host the simulation results:
  #+begin_src shell :session *shell* :results output :exports both 
  mkdir -p /root/simutools09/01-onelink/bin
  mkdir -p /root/simutools09/01-onelink/dat
  mkdir -p /root/simutools09/01-onelink/log
  mkdir -p /root/simutools09/01-onelink/tmp
  #+end_src
- Then outside the container, we copy the template input files and
  simulation perl script:
  # :var CONTAINER=container
  #+begin_src shell :results output :exports both
  docker cp simutools09/instructions/01-onelink/onelink-d-template.xml \
	 $CONTAINER:/root/simutools09/01-onelink
  docker cp simutools09/instructions/01-onelink/onelink-p-template.xml \
	 $CONTAINER:/root/simutools09/01-onelink
  docker cp simutools09/instructions/01-onelink/bin/sweep-parse.pl \
	 $CONTAINER:/root/simutools09/01-onelink/bin/sweep-parse.pl
  #+end_src
- And finally back inside the container, we fix the absolute paths
  before running the simulations:
#   sed -i 's|/home/velho/Development/projet-simgrid/simgrid/examples/msg/gtnets|/root/simgrid-3.3/examples/msg/gtnets|g' \
#        /root/simutools09/01-onelink/bin/sweep-parse.pl
  #+begin_src shell :session *shell* :results output :exports both 
  old_path="/home/velho/Development/projet-simgrid/simgrid/examples/msg/gtnets"
  new_path="/root/simgrid-3.3/examples/msg/gtnets"
  sed -i "s|$old_path|$new_path|g" /root/simutools09/01-onelink/bin/sweep-parse.pl
  cd /root/simutools09/01-onelink/
  ./bin/sweep-parse.pl sweep 1 1
  #+end_src

  #+RESULTS:
  : Bandiwthd array size is : 43
  : Changing working directory to /root/simgrid-3.3/examples/msg/gtnets
  : =============================================================<
  : Bandwidth (B) : 1.000000e+05 B/s (Bytes per second)
  : Latency   (L) : 0.00001 s (seconds)
  : Size      (S) : 1000 B (Bytes)
  : ...

  This worked like a charm! Unfortunately, according to the script,
  there are $40\times15= 600$ (latency, bw) combinations, which run each
  for a bit more than a minute, hence about 10 hours solely for the
  first series of experiments. We did not let it run to the end but we
  checked that the parsing works and that all results matched for a
  hundred of combinations.

** Running the analysis of the first series of experiments.
The analysis depends on master R script
(=simutools09/instructions/01-onelink/analyze.R=) which invokes perl and
gnuplot. This is ugly but all pretty standard so we decided there was
no need to rebuild a dedicated analysis environment and that it should
run directly on our machine. To avoid messing up with the content of the
original data, we decided to work in the =/tmp= of our machine as
follows:

# :var CONTAINER=container
#+begin_src shell :results output :exports both 
mkdir -p /tmp/simutools09/01-onelink/dat/
mkdir -p /tmp/simutools09/01-onelink/log/
mkdir -p /tmp/simutools09/01-onelink/tmp/
mkdir -p /tmp/simutools09/01-onelink/bin/
docker cp $CONTAINER:/root/simutools09/01-onelink/dat/raw.data /tmp/simutools09/01-onelink/dat/
cp simutools09/instructions/01-onelink/analyze.R /tmp/simutools09/01-onelink/
cp simutools09/instructions/01-onelink/bin/* /tmp/simutools09/01-onelink/bin/
#+end_src

#+begin_src R :results output :session *R* :exports both :dir /tmp/simutools09/01-onelink/
source("analyze.R");
#+end_src

#+RESULTS:
#+begin_example
# Latency (SECONDS) Size (BYTES) Time (SECONDS) 
Relax this may take some time
...........................................................
...........................................................
...........................................................
..................................................
Cadidates are X=0.934752791154703 and Y=10.6510810055123
The min is approximatelly: 0.0466609377572045
[1] "Hello!!!"
-Inf & NaN & NA \\ 
-Inf & NaN & NA \\ 
-Inf & NaN & NA \\ 
-Inf & NaN & NA \\ 
-Inf & NaN & NA \\ 
-Inf & NaN & NA \\ 
9.524 87.72 490.2 905.8 989.7   999 999.9-Inf & NaN & NA \\ 
-Inf & NaN & NA \\ 
-Inf & NaN & NA \\ 
-Inf & NaN & NA \\ 
"./tmp/gnuplotError.script" line 4: undefined variable: Inf

"./tmp/gnuplotError.script" line 4: undefined variable: Inf

There were 15 warnings (use warnings() to see them)
#+end_example

When running, a gnuplot window with a 3D graph popped up. There are
error messages but the "~Cadidates are X=0.934752791154703 and
Y=10.6510810055123~" message is really nice as these are the latency
and bandwidth modifiers obtained through a custom linear regression
and this is very familiar. The original paper reports ~.92~ and ~10.4~
(page 5). The warnings and the differences come from the fact that the regression we
just run was done using a smaller set of simulations because we didn't
want to waste our time rerunning all the simulations.

* Conclusion and take-away messages
Although we only replicated a fraction of the simulations conducted in
the original article, they all perfectly match and we are confident
that all the results would be reproduced with a few additional hours
of efforts and enough time to run all the simulations (several days
actually). This is of little interest as GTNetS has been replaced in
earlier versions of SimGrid by an other packet level simulator: [[http://www.nsnam.org][NS3]].

We have shown in this article how to use modern tools such as the
[[https://hub.docker.com/][Docker Hub]], the [[https://snapshot.debian.org/][Debian snapshot archive]], the [[https://github.com/debuerreotype/debuerreotype][Debuerreotype]], [[http://github.com/][GitHub]],
and [[https://www.softwareheritage.org/][Software Heritage]]. We have tried to demonstrate best practices and
to highlight their effectiveness or potential shortcomings. Although
they all require a relatively high level of operating system
understanding and expertise, we believe they are all now mature enough
and sufficiently easy to use both for such kind of computer
"archaeology" and for a daily usage in a research context (, which
greatly eases the task of anyone trying to reuse or reproduce the
work).

A sound question to ask is: "Would anyone other than the original
authors have succeeded in reproducing this work?". A fair answer is
probably no. 
- First, three different archives were needed: the first one was easy
  to find, the second one was publicly available but deeply hidden so
  it is unlikely anyone else than the original authors would have
  found it, and although the third one was also available on the
  Internet, it was not very visible and we initially recovered from
  the hard drive of one of the two original authors.
- Second, even after gathering the three archives, rebuilding the
  software environment, correctly linking and running the simulation
  was possible but required such a good amount of faith that we
  believe anyone else than the original authors would have easily
  given up.

At the time of writing of the original article, Pedro Velho had put a
significant effort in documenting the whole workflow and relying on
standard tools such as =R=, =perl=, and =make= to automate as much work as
possible. Yet, we made the three following mistakes from a
reproducibility perspective:
1. We never reached the point where a full automation was done and
   delegated to a third party. In particular as we had no satisfying
   nor standard tool to distribute the workload on a cluster. So we
   kept track of simulation outputs and intermediate results
   manually. This good organization has been a life saver when trying
   to reproduce and check the results. If we had to redo such work
   today, we would probably use something like [[https://snakemake.readthedocs.io/][=snakemake=]] and
   [[http://orgmode.org/][=org-mode=]] notebooks to easily automate and document the whole
   work.
2. We underestimated the [[https://en.wikipedia.org/wiki/Link_rot][URL rot]] effect. Although all our work was
   version controlled, moving from a development platform to an other
   made information and archive retrieval more difficult than we
   anticipate. Although all the archives were finally available, it
   took us an inordinate amount of time to locate them.. Cleaning up
   is rarely done after publishing, hence the need to do it on the
   fly. It turns out that Pedro Velho had taken care to clean and to
   make all the data he had produced during his PhD thesis available
   on his [[http://mescal.imag.fr/membres/pedro.velho/publications.html][webpage]]. The policy in our lab is to maintain the webpage of
   former members so all the data is still available but not easily
   found. Using a perennial archive such as [[http://zenodo.org/][Zenodo]] would be the
   recommended way to proceed nowadays but this archive did not exist
   by then.
3. Finally, we underestimated the importance of capturing every
   information on software environment. A few ones related to
   processor architecture and compilers were available but it was
   lacunar. Fortunately, we only relied on standard open source
   software and from the dates, it was not too hard to identify which
   software must have been used and we have been able to rebuild a
   functional software environment at low cost, solely from binary
   packages. Controlling this environment and making it easily
   available and usable is definitely the way to go with tools like
   [[https://hub.docker.com/][Docker]] but this lightweight virtualization was not as easy to use
   back then.
Overall this reproducibility challenge was an excellent experience to
face the effect of time even on a relatively short (10 years) time
period. It was also very positive to realize that over the last
decade, several very good tools and practices have emerged to address
exactly the difficulties we faced back then (workflows and notebooks
to handle computations, software and data archives to fight against
link rot, container and stable packaging systems to manage software
environments).

* Emacs setup                                                      :noexport:
# Local Variables:
# eval:    (require 'org-install)
# eval:    (org-babel-do-load-languages 'org-babel-load-languages '( (shell . t) (R . t) (perl . t) (ditaa . t) ))
# eval:    (add-to-list 'org-latex-packages-alist '("" "minted"))
# eval:    (setq org-latex-listings 'minted)
# eval:    (setq org-latex-minted-options '(("bgcolor" "grispale") ("frame" "lines") ("linenos" "true") ("fontsize" "\\small")))
# eval:    (setq org-latex-pdf-process '("lualatex -shell-escape -interaction nonstopmode -output-directory %o %f"))
# eval:    (setq org-alphabetical-lists t)
# eval:    (setq org-src-fontify-natively t)
# eval:    (setq ispell-local-dictionary "american")
# eval:    (eval (flyspell-mode t))
# End:

